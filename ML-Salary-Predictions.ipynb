{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9cdcc60",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "## Salary Prediction for Data Professions using Machine Learning\n",
    "\n",
    "\n",
    "### üî¥ Important: Read before proceeding ‚¨áÔ∏è\n",
    "### To create and view stats on various types of models run steps 1-13.\n",
    "### To create and save a model locally using pipeline run steps 1-5 and then step 8 and finally steps 14-15.\n",
    "\n",
    "\n",
    "### Step 1 - Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137144b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data Manipulation and Visualisation Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing Data Preprocessing Libraries\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "\n",
    "# Importing SkLearn ML Model Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c778dd2",
   "metadata": {},
   "source": [
    "### Step 2 - Load The Dataset Into The Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('salary_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1337b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"First 5 lines of dataset\\n\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\n\\n\\nRows and Columns in dataset\\n\")\n",
    "print(df.shape)\n",
    "\n",
    "print(f\"\\n\\n\\nInformation about the dataset\\n\")\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eadaa0",
   "metadata": {},
   "source": [
    "### Step 3 - Clean Some Of The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee74d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d912fb4",
   "metadata": {},
   "source": [
    "### Step 4 - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d9f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Experience of an Individual\n",
    "df['DOJ'] = pd.to_datetime(df['DOJ'])\n",
    "df['CURRENT DATE'] = pd.to_datetime(df['CURRENT DATE'])\n",
    "df['EXPERIENCE'] = df['CURRENT DATE'].dt.year - df['DOJ'].dt.year\n",
    "\n",
    "# Dropping irrelevant columns\n",
    "df = df.drop(columns=['FIRST NAME', 'LAST NAME', 'DOJ', 'CURRENT DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eed405",
   "metadata": {},
   "source": [
    "### Step 5 - Split Data Into Training And Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89abcbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data\n",
    "X = df.drop('SALARY', axis=1)\n",
    "y = df['SALARY']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ae97ff",
   "metadata": {},
   "source": [
    "## Run The Below Code Only If You Want Stats Of Different Models\n",
    "### Step 6 - Encode The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d2b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding\n",
    "order = [['Analyst', 'Senior Analyst', 'Associate', 'Manager', 'Senior Manager', 'Director']]\n",
    "oencoder = OrdinalEncoder(categories = order)\n",
    "X_train['DESIGNATION'] = oencoder.fit_transform(X_train[['DESIGNATION']])\n",
    "X_test['DESIGNATION'] = oencoder.transform(X_test[['DESIGNATION']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b88581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "labelColumns = ['SEX', 'UNIT']\n",
    "for col in labelColumns:\n",
    "    lencoder = LabelEncoder()\n",
    "    X_train[col] = lencoder.fit_transform(X_train[col])\n",
    "    X_test[col] = lencoder.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2054b",
   "metadata": {},
   "source": [
    "### Step 7 - Select The Best Features And Reassign Only Them To The Training And Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a687f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "featureSelector = SelectKBest(score_func = f_regression, k = 5)\n",
    "X_train = featureSelector.fit_transform(X_train, y_train)\n",
    "X_test = featureSelector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns = featureSelector.get_feature_names_out())\n",
    "X_test = pd.DataFrame(X_test, columns = featureSelector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1273d",
   "metadata": {},
   "source": [
    "### Step 8 - Perform Correlation Analysis And Adjust Training And Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90dab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "matrix = X_train.corr(numeric_only=True)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(matrix, annot=True)\n",
    "plt.title('Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d558ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = ['AGE'])\n",
    "X_test = X_test.drop(columns = ['AGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99436157",
   "metadata": {},
   "source": [
    "### Step 9 - Write Helper Functions For Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5200ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "def findScores(y_test, predictions):\n",
    "    return [metrics.mean_absolute_error(y_test, predictions), metrics.mean_squared_error(y_test, predictions), np.sqrt(metrics.mean_squared_error(y_test, predictions)), metrics.r2_score(y_test, predictions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8617f06",
   "metadata": {},
   "source": [
    "### Step 10 - Use Linear Regression To Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85810430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearRegression\n",
    "linearRegressor = LinearRegression()\n",
    "linearRegressor.fit(X_train, y_train)\n",
    "predictionslr = linearRegressor.predict(X_test)\n",
    "\n",
    "findScores(y_test, predictionslr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b304fb31",
   "metadata": {},
   "source": [
    "### Step 11 - Use A Random Forest Regressor To Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb7367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "randomForest = RandomForestRegressor(n_estimators = 110)\n",
    "randomForest.fit(X_train, y_train)\n",
    "predictionsrf = randomForest.predict(X_test)\n",
    "\n",
    "findScores(y_test, predictionsrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad27903",
   "metadata": {},
   "source": [
    "### Step 12 - Use A Decision Tree Regressor To Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19514044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTree\n",
    "dtRegressor = DecisionTreeRegressor()\n",
    "dtRegressor.fit(X_train, y_train)\n",
    "predictionsdt = dtRegressor.predict(X_test)\n",
    "\n",
    "findScores(y_test, predictionsdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d3e6f7",
   "metadata": {},
   "source": [
    "### Step 13 - Use A Gradient Boosting Regressor To Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891df063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoosting\n",
    "gradientBooster = GradientBoostingRegressor()\n",
    "gradientBooster.fit(X_train, y_train)\n",
    "predictionsgb = gradientBooster.predict(X_test)\n",
    "findScores(y_test, predictionsgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244400cc",
   "metadata": {},
   "source": [
    "## Continue Below To Create And Save Model\n",
    "\n",
    "\n",
    "### Step 14 - Remove Columns Not Needed In Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1984745",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = ['LEAVES USED', 'LEAVES REMAINING', 'RATINGS'])\n",
    "X_test = X_test.drop(columns = ['LEAVES USED', 'LEAVES REMAINING', 'RATINGS'])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b5c55a",
   "metadata": {},
   "source": [
    "### Step 15 - Create A Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [['Analyst', 'Senior Analyst', 'Associate', 'Manager', 'Senior Manager', 'Director']]\n",
    "oColumnsOrder = ['DESIGNATION']\n",
    "oColumnsNonOrder = ['SEX','UNIT']\n",
    "transformer1 = ColumnTransformer([('ordinal-encoding-order-based', OrdinalEncoder(categories = order), oColumnsOrder),('ordinal-encoding-no-order', OrdinalEncoder(), oColumnsNonOrder)], remainder='passthrough')\n",
    "\n",
    "transformer2 = SelectKBest(f_regression, k = 5)\n",
    "\n",
    "transformer3 = GradientBoostingRegressor()\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessing', transformer1), ('feature_selection', transformer2), ('model', transformer3)])\n",
    "pipeline.fit(X_train, y_train)\n",
    "pickle.dump(pipeline, open('salaryPredictionModel.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
